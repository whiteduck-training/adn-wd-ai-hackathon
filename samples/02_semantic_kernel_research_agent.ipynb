{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # üîß Semantic Kernel Tool Use Example ‚Äì Research Assistant\n",
    "\n",
    "\n",
    "\n",
    " Welcome to this **Semantic Kernel Tool Use** sample! This code demonstrates how to build a powerful **Research Assistant** using the Semantic Kernel framework. You'll learn how to create an AI agent that can search for academic papers, perform web searches, generate summaries, and create visualizations.\n",
    "\n",
    "\n",
    "\n",
    " ## üéØ **Objective**\n",
    "\n",
    "\n",
    "\n",
    " The goal of this sample is to demonstrate how to:\n",
    "\n",
    " - Create and register **custom plugins** as tools for your AI agent\n",
    "\n",
    " - Configure **function calling behavior** to control how your agent uses tools\n",
    "\n",
    " - Build a complete **research assistant** that can gather and analyze information\n",
    "\n",
    " - Implement an **interactive UI** for engaging with your AI agent\n",
    "\n",
    "\n",
    "\n",
    " ## üß© **Why Plugins Matter**\n",
    "\n",
    "\n",
    "\n",
    " Plugins in Semantic Kernel are essential because they:\n",
    "\n",
    " - Extend your AI agent's capabilities beyond just conversation\n",
    "\n",
    " - Allow your agent to interact with external systems and APIs\n",
    "\n",
    " - Enable complex workflows by combining multiple tools\n",
    "\n",
    " - Create a modular architecture that's easy to maintain and expand\n",
    "\n",
    "\n",
    "\n",
    " ## üîÑ **Function Calling Behavior**\n",
    "\n",
    "\n",
    "\n",
    " This sample demonstrates how to control when and how your agent uses tools through:\n",
    "\n",
    " - **Auto-invocation** of functions when the agent decides they're needed\n",
    "\n",
    " - **Required function choice** to ensure the agent uses available tools\n",
    "\n",
    " - **Maximum invocation attempts** to prevent infinite loops\n",
    "\n",
    "\n",
    "\n",
    " ## üí° **Key Takeaways from this Sample**\n",
    "\n",
    "\n",
    "\n",
    " - Learn how to create custom plugins with multiple functions\n",
    "\n",
    " - Understand how to configure function calling behavior\n",
    "\n",
    " - See how to build a complete research workflow with multiple tools\n",
    "\n",
    " - Explore techniques for creating interactive AI agent interfaces\n",
    "\n",
    "\n",
    "\n",
    " Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üì¶ Import the Needed Packages\n",
    "\n",
    "\n",
    "\n",
    " We'll start by importing all the necessary libraries for our research assistant. These include:\n",
    "\n",
    "\n",
    "\n",
    " - **Semantic Kernel core components** for building our agent\n",
    "\n",
    " - **External APIs** for searching academic papers and the web\n",
    "\n",
    " - **Data processing libraries** for handling and visualizing information\n",
    "\n",
    " - **UI components** for creating an interactive interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import asyncio\n",
    "import json\n",
    "import re\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Annotated\n",
    "\n",
    "# Third-party imports\n",
    "import arxiv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from duckduckgo_search import DDGS\n",
    "import markdownify\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Semantic Kernel imports\n",
    "from semantic_kernel.functions import kernel_function\n",
    "from semantic_kernel.kernel import Kernel, KernelArguments\n",
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.contents.function_call_content import FunctionCallContent\n",
    "from semantic_kernel.contents.function_result_content import FunctionResultContent\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import (\n",
    "    FunctionChoiceBehavior,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ServiceInitializationError",
     "evalue": "chat_deployment_name is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mServiceInitializationError\u001b[0m                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Initialize kernel and service\u001b[39;00m\n\u001b[0;32m     15\u001b[0m kernel \u001b[38;5;241m=\u001b[39m Kernel()\n\u001b[1;32m---> 16\u001b[0m kernel\u001b[38;5;241m.\u001b[39madd_service(\u001b[43mAzureChatCompletion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSERVICE_ID\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     17\u001b[0m settings \u001b[38;5;241m=\u001b[39m kernel\u001b[38;5;241m.\u001b[39mget_prompt_execution_settings_from_service_id(service_id\u001b[38;5;241m=\u001b[39mSERVICE_ID)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Create necessary directories\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aratz\\adn-wd-ai-hackathon\\.venv\\Lib\\site-packages\\semantic_kernel\\connectors\\ai\\open_ai\\services\\azure_chat_completion.py:99\u001b[0m, in \u001b[0;36mAzureChatCompletion.__init__\u001b[1;34m(self, service_id, api_key, deployment_name, endpoint, base_url, api_version, ad_token, ad_token_provider, token_endpoint, default_headers, async_client, env_file_path, env_file_encoding, instruction_role)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to validate settings: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m azure_openai_settings\u001b[38;5;241m.\u001b[39mchat_deployment_name:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ServiceInitializationError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchat_deployment_name is required.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    102\u001b[0m     deployment_name\u001b[38;5;241m=\u001b[39mazure_openai_settings\u001b[38;5;241m.\u001b[39mchat_deployment_name,\n\u001b[0;32m    103\u001b[0m     endpoint\u001b[38;5;241m=\u001b[39mazure_openai_settings\u001b[38;5;241m.\u001b[39mendpoint,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m     instruction_role\u001b[38;5;241m=\u001b[39minstruction_role,\n\u001b[0;32m    115\u001b[0m )\n",
      "\u001b[1;31mServiceInitializationError\u001b[0m: chat_deployment_name is required."
     ]
    }
   ],
   "source": [
    "# Initialize constants\n",
    "SERVICE_ID = \"agent\"\n",
    "OUTPUT_DIRS = [\"papers\", \"visualizations\", \"summaries\"]\n",
    "\n",
    "\n",
    "def create_directories():\n",
    "    \"\"\"Create directories for saving files.\"\"\"\n",
    "    for directory in OUTPUT_DIRS:\n",
    "        os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    print(f\"Created directories: {', '.join(OUTPUT_DIRS)}\")\n",
    "\n",
    "\n",
    "# Initialize kernel and service\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=SERVICE_ID))\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(service_id=SERVICE_ID)\n",
    "\n",
    "# Create necessary directories\n",
    "create_directories()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üèóÔ∏è **Setting Up the Environment**\n",
    "\n",
    "\n",
    "\n",
    " Before we start building our research assistant, we need to set up a directory structure to store:\n",
    "\n",
    " - Downloaded academic papers\n",
    "\n",
    " - Generated visualizations\n",
    "\n",
    " - Research summaries and web content\n",
    "\n",
    "\n",
    "\n",
    " The `create_directories()` function ensures these folders exist, creating them if necessary.\n",
    "\n",
    "\n",
    "\n",
    " This organization helps maintain a clean project structure and makes it easy to find and manage the files our research assistant will generate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üîå **Creating the Plugins**\n",
    "\n",
    "\n",
    "\n",
    " Semantic Kernel uses plugins as tools that can be called by the agent. A plugin can have multiple `kernel_functions` in it as a group.\n",
    "\n",
    "\n",
    "\n",
    " In this example, we'll create several plugins that work together to form a complete research workflow:\n",
    "\n",
    " 1. **ArXivPlugin** - Searches for and downloads academic papers\n",
    "\n",
    " 2. **WebSearchPlugin** - Performs web searches and extracts content from web pages\n",
    "\n",
    " 3. **ResearchPlugin** - Generates research summaries from collected information\n",
    "\n",
    " 4. **VisualizationPlugin** - Creates data visualizations to help understand research topics\n",
    "\n",
    "\n",
    "\n",
    " Each plugin contains one or more functions decorated with `@kernel_function`, which makes them available to the AI agent.\n",
    "\n",
    "\n",
    "\n",
    " ### üí° **Why Use Multiple Plugins?**\n",
    "\n",
    " - **Separation of concerns** - Each plugin handles a specific aspect of the research process\n",
    "\n",
    " - **Modularity** - Plugins can be reused across different projects\n",
    "\n",
    " - **Maintainability** - Easier to update or extend individual components\n",
    "\n",
    " - **Clarity** - Makes the agent's capabilities more explicit and organized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ArXiv Search Plugin with PDF download\n",
    "class ArXivPlugin:\n",
    "    \"\"\"Plugin for searching academic papers on arXiv and downloading PDFs.\"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Search for academic papers on arXiv based on a query.\"\n",
    "    )\n",
    "    def search_papers(\n",
    "        self,\n",
    "        query: Annotated[str, \"The research topic to search for on arXiv.\"],\n",
    "        max_results: Annotated[int, \"Maximum number of results to return.\"] = 5,\n",
    "    ) -> Annotated[str, \"JSON string of arXiv paper results.\"]:\n",
    "        \"\"\"Search for papers on arXiv related to the query.\"\"\"\n",
    "        try:\n",
    "            # Search arXiv\n",
    "            search = arxiv.Search(\n",
    "                query=query,\n",
    "                max_results=max_results,\n",
    "                sort_by=arxiv.SortCriterion.Relevance,\n",
    "            )\n",
    "\n",
    "            results = []\n",
    "            for paper in search.results():\n",
    "                # Format the authors and prepare filename\n",
    "                authors = \", \".join([author.name for author in paper.authors])\n",
    "                arxiv_id = paper.entry_id.split(\"/\")[-1]\n",
    "\n",
    "                # Create a clean filename from the title\n",
    "                clean_title = re.sub(r\"[^\\w\\s-]\", \"\", paper.title)\n",
    "                clean_title = re.sub(r\"[-\\s]+\", \"-\", clean_title).strip(\"-\")[:50]\n",
    "                filename = f\"{arxiv_id}_{clean_title}.pdf\"\n",
    "                filepath = os.path.join(\"papers\", filename)\n",
    "\n",
    "                # Download the PDF file\n",
    "                try:\n",
    "                    paper.download_pdf(\"papers\")\n",
    "                    download_status = \"success\"\n",
    "                except Exception as e:\n",
    "                    download_status = f\"failed: {str(e)}\"\n",
    "\n",
    "                # Add paper information to results\n",
    "                results.append(\n",
    "                    {\n",
    "                        \"title\": paper.title,\n",
    "                        \"authors\": authors,\n",
    "                        \"summary\": paper.summary.replace(\"\\n\", \" \"),\n",
    "                        \"published\": paper.published.strftime(\"%Y-%m-%d\"),\n",
    "                        \"url\": paper.pdf_url,\n",
    "                        \"arxiv_id\": arxiv_id,\n",
    "                        \"local_path\": filepath\n",
    "                        if download_status == \"success\"\n",
    "                        else None,\n",
    "                        \"download_status\": download_status,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            if not results:\n",
    "                return json.dumps(\n",
    "                    {\n",
    "                        \"status\": \"no_results\",\n",
    "                        \"message\": \"No papers found on arXiv for this query.\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            return json.dumps({\"status\": \"success\", \"papers\": results}, indent=2)\n",
    "\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"status\": \"error\", \"message\": str(e)})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### üåê **Web Search Plugin**\n",
    "\n",
    "\n",
    "\n",
    " The **WebSearchPlugin** extends our research capabilities beyond academic papers by:\n",
    "\n",
    " - Searching the web using DuckDuckGo's API\n",
    "\n",
    " - Extracting and processing content from web pages\n",
    "\n",
    " - Converting HTML content to markdown for easier processing\n",
    "\n",
    " - Saving web content to files for future reference\n",
    "\n",
    "\n",
    "\n",
    " This plugin is particularly useful when:\n",
    "\n",
    " - Academic papers don't provide enough information\n",
    "\n",
    " - We need more recent information than what's available in published papers\n",
    "\n",
    " - We want to include non-academic perspectives on a topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebSearchPlugin:\n",
    "    \"\"\"Plugin for web search using DuckDuckGo.\"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Search the web using DuckDuckGo.\")\n",
    "    def search_web(\n",
    "        self,\n",
    "        query: Annotated[str, \"The search query to look up.\"],\n",
    "        max_results: Annotated[int, \"Maximum number of results to return.\"] = 5,\n",
    "    ) -> Annotated[str, \"JSON string of web search results.\"]:\n",
    "        \"\"\"Perform a web search using DuckDuckGo for a given query.\"\"\"\n",
    "        try:\n",
    "            ddgs = DDGS()\n",
    "            results = list(ddgs.text(query, max_results=max_results))\n",
    "\n",
    "            if not results:\n",
    "                return json.dumps(\n",
    "                    {\n",
    "                        \"status\": \"no_results\",\n",
    "                        \"message\": \"No web results found for this query.\",\n",
    "                    }\n",
    "                )\n",
    "\n",
    "            return json.dumps({\"status\": \"success\", \"results\": results}, indent=2)\n",
    "\n",
    "        except Exception as e:\n",
    "            return json.dumps({\"status\": \"error\", \"message\": str(e)})\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Get the content of a web page and convert it to markdown.\"\n",
    "    )\n",
    "    def get_page_content(\n",
    "        self, url: Annotated[str, \"The URL of the web page to extract content from.\"]\n",
    "    ) -> Annotated[str, \"Markdown content of the web page.\"]:\n",
    "        \"\"\"Extract content from a web page and convert it to markdown.\"\"\"\n",
    "        try:\n",
    "            import requests\n",
    "            from bs4 import BeautifulSoup\n",
    "\n",
    "            # Set up request headers for a standard browser\n",
    "            headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "\n",
    "            # Get the web page content\n",
    "            response = requests.get(url, headers=headers, timeout=10)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            # Parse the HTML content\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "            # Remove script and style elements that aren't needed\n",
    "            for element in soup([\"script\", \"style\"]):\n",
    "                element.extract()\n",
    "\n",
    "            # Try to find the main content using common HTML5 semantic elements\n",
    "            # Fall back to body if no semantic elements are found\n",
    "            main_content = (\n",
    "                soup.find(\"main\") or soup.find(\"article\") or soup.find(\"body\")\n",
    "            )\n",
    "\n",
    "            if not main_content:\n",
    "                return \"Could not extract meaningful content from the page.\"\n",
    "\n",
    "            # Convert to markdown\n",
    "            md = markdownify.markdownify(str(main_content), heading_style=\"ATX\")\n",
    "\n",
    "            # Generate a unique filename with timestamp\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"web_content_{timestamp}.md\"\n",
    "            filepath = os.path.join(\"summaries\", filename)\n",
    "\n",
    "            # Save the full content to a file\n",
    "            with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(f\"# Content from {url}\\n\\n\")\n",
    "                f.write(md)\n",
    "\n",
    "            # Truncate content for return value if it's too long\n",
    "            # 25,000 chars is approximately 5000 words\n",
    "            MAX_CONTENT_LENGTH = 25000\n",
    "            if len(md) > MAX_CONTENT_LENGTH:\n",
    "                md = (\n",
    "                    md[:MAX_CONTENT_LENGTH]\n",
    "                    + \"\\n\\n... (content truncated due to length)\"\n",
    "                )\n",
    "\n",
    "            return (\n",
    "                f\"Content extracted and saved to {filepath}. Preview:\\n\\n{md[:1000]}...\"\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error retrieving or processing web page: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### üìù **Research Plugin**\n",
    "\n",
    "\n",
    "\n",
    " The **ResearchPlugin** helps synthesize information from multiple sources into a coherent summary. In a real-world implementation, this would likely use an LLM to:\n",
    "\n",
    " - Analyze content from academic papers and web searches\n",
    "\n",
    " - Identify key findings and methodologies\n",
    "\n",
    " - Generate a structured research summary\n",
    "\n",
    " - Save the summary to a file for future reference\n",
    "\n",
    "\n",
    "\n",
    " This plugin demonstrates how Semantic Kernel can be used to create higher-level cognitive functions that build on the data gathering capabilities of other plugins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchPlugin:\n",
    "    \"\"\"Plugin for analyzing research information and generating summaries.\"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Generate a research summary from papers and web content.\"\n",
    "    )\n",
    "    def generate_summary(\n",
    "        self,\n",
    "        topic: Annotated[str, \"The research topic being investigated.\"],\n",
    "        papers_json: Annotated[str, \"JSON string of papers from arXiv (may be empty).\"],\n",
    "        web_content: Annotated[str, \"Content from web pages (may be empty).\"],\n",
    "    ) -> Annotated[str, \"A comprehensive research summary.\"]:\n",
    "        \"\"\"Generate a research summary and save it to a file.\"\"\"\n",
    "        # Create a summary template (in a real implementation, this would call an LLM)\n",
    "        summary_template = \"\"\"\n",
    "# Research Summary: {topic}\n",
    "\n",
    "## Sources\n",
    "The research summary is based on available papers from arXiv and web content related to the topic.\n",
    "\n",
    "## Key Findings\n",
    "- Finding 1 related to {topic}\n",
    "- Finding 2 related to {topic}\n",
    "- Finding 3 related to {topic}\n",
    "\n",
    "## Methodology\n",
    "Various research methodologies were observed across the literature...\n",
    "\n",
    "## Current State\n",
    "The current state of research on {topic}...\n",
    "\n",
    "## Future Directions\n",
    "Based on the analyzed content, future research might focus on...\n",
    "\n",
    "## Conclusion\n",
    "This research summary provides an overview of the current understanding of {topic}...\n",
    "\"\"\"\n",
    "        # Format the summary with the topic\n",
    "        summary = summary_template.format(topic=topic)\n",
    "\n",
    "        # Create a clean filename from the topic\n",
    "        clean_topic = re.sub(r\"[^\\w\\s-]\", \"\", topic)\n",
    "        clean_topic = re.sub(r\"[-\\s]+\", \"-\", clean_topic).strip(\"-\")\n",
    "\n",
    "        # Generate a unique filename with timestamp\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"summary_{clean_topic}_{timestamp}.md\"\n",
    "        filepath = os.path.join(\"summaries\", filename)\n",
    "\n",
    "        with open(filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(summary)\n",
    "\n",
    "        return f\"Research summary created and saved to {filepath}.\\n\\n{summary}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### üìä **Visualization Plugin**\n",
    "\n",
    "\n",
    "\n",
    " The **VisualizationPlugin** adds data visualization capabilities to our research assistant. It can:\n",
    "\n",
    " - Generate sample data based on a research topic\n",
    "\n",
    " - Create different types of charts (bar, line, scatter)\n",
    "\n",
    " - Save visualizations to disk for inclusion in reports\n",
    "\n",
    "\n",
    "\n",
    " Visualizations are powerful tools for understanding complex information and identifying patterns. This plugin demonstrates how Semantic Kernel can integrate with data visualization libraries like matplotlib and pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisualizationPlugin:\n",
    "    \"\"\"Plugin for creating visualizations from research data.\"\"\"\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Generate sample data for visualization based on a research topic.\"\n",
    "    )\n",
    "    def generate_visualization_data(\n",
    "        self, topic: Annotated[str, \"The research topic being visualized.\"]\n",
    "    ) -> Annotated[str, \"JSON data for visualization.\"]:\n",
    "        \"\"\"Generate sample data for visualization (simulated for this example).\"\"\"\n",
    "        # Extract words from the topic for category names\n",
    "        topic_words = re.findall(r\"\\w+\", topic.lower())\n",
    "\n",
    "        # Number of categories to generate\n",
    "        NUM_CATEGORIES = 5\n",
    "\n",
    "        # Generate category names based on topic words\n",
    "        categories = []\n",
    "        for i in range(NUM_CATEGORIES):\n",
    "            if topic_words:\n",
    "                word = random.choice(topic_words)\n",
    "                categories.append(f\"{word.capitalize()} {i+1}\")\n",
    "            else:\n",
    "                categories.append(f\"Category {i+1}\")\n",
    "\n",
    "        # Generate random metrics for visualization\n",
    "        impact_factor = [random.randint(10, 100) for _ in range(len(categories))]\n",
    "        research_activity = [random.randint(20, 80) for _ in range(len(categories))]\n",
    "\n",
    "        # Create the data structure for visualization\n",
    "        data = {\n",
    "            \"categories\": categories,\n",
    "            \"metrics\": {\n",
    "                \"Impact Factor\": impact_factor,\n",
    "                \"Research Activity\": research_activity,\n",
    "            },\n",
    "        }\n",
    "\n",
    "        return json.dumps(data, indent=2)\n",
    "\n",
    "    @kernel_function(\n",
    "        description=\"Create a visualization from provided data and save it to disk.\"\n",
    "    )\n",
    "    def create_visualization(\n",
    "        self,\n",
    "        data_json: Annotated[str, \"JSON data for visualization.\"],\n",
    "        chart_type: Annotated[\n",
    "            str, \"Type of chart to create (bar, line, scatter, etc.).\"\n",
    "        ] = \"bar\",\n",
    "        topic: Annotated[\n",
    "            str, \"The research topic for the chart title.\"\n",
    "        ] = \"Research Topic\",\n",
    "    ) -> Annotated[str, \"Path to the saved visualization.\"]:\n",
    "        \"\"\"Create a visualization from the provided data and save it to disk.\"\"\"\n",
    "        try:\n",
    "            # Parse the JSON data\n",
    "            data = json.loads(data_json)\n",
    "\n",
    "            # Set the style\n",
    "            plt.style.use(\"ggplot\")\n",
    "\n",
    "            # Create figure\n",
    "            plt.figure(figsize=(10, 6))\n",
    "\n",
    "            # Extract data\n",
    "            categories = data[\"categories\"]\n",
    "            metrics = data[\"metrics\"]\n",
    "\n",
    "            # Create a clean filename from the topic\n",
    "            clean_topic = re.sub(r\"[^\\w\\s-]\", \"\", topic)\n",
    "            clean_topic = re.sub(r\"[-\\s]+\", \"-\", clean_topic).strip(\"-\")\n",
    "\n",
    "            # Generate a timestamp for unique filenames\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "            # Determine chart type and create visualization\n",
    "            if chart_type == \"bar\":\n",
    "                # Set up the data for plotting\n",
    "                df = pd.DataFrame({\"Categories\": categories, **metrics})\n",
    "                df.set_index(\"Categories\", inplace=True)\n",
    "\n",
    "                # Create the bar chart with rotated x-axis labels\n",
    "                ax = df.plot(kind=\"bar\", rot=45)\n",
    "                plt.title(f\"{topic} - Research Metrics by Category\")\n",
    "                plt.ylabel(\"Value\")\n",
    "                plt.legend(title=\"Metrics\")\n",
    "                filename = f\"bar_chart_{clean_topic}_{timestamp}.png\"\n",
    "\n",
    "            elif chart_type == \"line\":\n",
    "                # Set up the data for plotting\n",
    "                df = pd.DataFrame({\"Categories\": categories, **metrics})\n",
    "                df.set_index(\"Categories\", inplace=True)\n",
    "\n",
    "                # Create the line chart with markers at data points\n",
    "                ax = df.plot(kind=\"line\", marker=\"o\")\n",
    "                plt.title(f\"{topic} - Research Metrics Trend by Category\")\n",
    "                plt.ylabel(\"Value\")\n",
    "                plt.legend(title=\"Metrics\")\n",
    "                filename = f\"line_chart_{clean_topic}_{timestamp}.png\"\n",
    "\n",
    "            elif chart_type == \"scatter\":\n",
    "                # For scatter, we need exactly two metrics\n",
    "                if len(metrics) >= 2:\n",
    "                    metric_names = list(metrics.keys())\n",
    "                    x_values = metrics[metric_names[0]]\n",
    "                    y_values = metrics[metric_names[1]]\n",
    "\n",
    "                    plt.scatter(x_values, y_values)\n",
    "                    plt.xlabel(metric_names[0])\n",
    "                    plt.ylabel(metric_names[1])\n",
    "                    plt.title(\n",
    "                        f\"{topic} - Correlation between {metric_names[0]} and {metric_names[1]}\"\n",
    "                    )\n",
    "\n",
    "                    # Add category labels to each point in the scatter plot\n",
    "                    for i, category in enumerate(categories):\n",
    "                        plt.annotate(\n",
    "                            category,  # Text label\n",
    "                            (x_values[i], y_values[i]),  # Point position\n",
    "                            textcoords=\"offset points\",  # How to position text\n",
    "                            xytext=(0, 10),  # Text offset\n",
    "                            ha=\"center\",  # Horizontal alignment\n",
    "                        )\n",
    "\n",
    "                    filename = f\"scatter_chart_{clean_topic}_{timestamp}.png\"\n",
    "                else:\n",
    "                    return \"Scatter plot requires at least two metrics.\"\n",
    "            else:\n",
    "                return f\"Unsupported chart type: {chart_type}\"\n",
    "\n",
    "            # Save the chart to disk\n",
    "            filepath = os.path.join(\"visualizations\", filename)\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(filepath, dpi=300)\n",
    "            plt.close()\n",
    "\n",
    "            return f\"Visualization created and saved to {filepath}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            return f\"Error creating visualization: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## ü§ñ **Creating a Conversation Helper**\n",
    "\n",
    "\n",
    "\n",
    " The `continue_research_conversation` function helps manage the conversation flow between the user and the research assistant. It:\n",
    "\n",
    " - Adds the user's message to the chat history\n",
    "\n",
    " - Streams the agent's response, filtering out function calls and results\n",
    "\n",
    " - Returns the updated chat history for future interactions\n",
    "\n",
    "\n",
    "\n",
    " This function demonstrates how to handle streaming responses from Semantic Kernel agents, which is important for providing a responsive user experience, especially when the agent is performing complex operations like searching for papers or generating visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def continue_research_conversation(agent, chat_history, user_message):\n",
    "    \"\"\"\n",
    "    Process a user message and stream the agent's response.\n",
    "\n",
    "    Args:\n",
    "        agent: The ChatCompletionAgent to use for generating responses\n",
    "        chat_history: The conversation history to add to\n",
    "        user_message: The new message from the user\n",
    "\n",
    "    Returns:\n",
    "        The updated chat history\n",
    "    \"\"\"\n",
    "    # Add the user's message to the chat history\n",
    "    chat_history.add_user_message(user_message)\n",
    "    print(f\"# User: '{user_message}'\")\n",
    "\n",
    "    # Start streaming the agent's response\n",
    "    print(\"# ResearchAssistant: '\", end=\"\")\n",
    "\n",
    "    # Process the response stream\n",
    "    async for content in agent.invoke_stream(chat_history):\n",
    "        # Only print non-function content (skip function calls and results)\n",
    "        is_function_content = any(\n",
    "            isinstance(item, (FunctionCallContent, FunctionResultContent))\n",
    "            for item in content.items\n",
    "        )\n",
    "\n",
    "        if not is_function_content and content.content.strip():\n",
    "            print(f\"{content.content}\", end=\"\", flush=True)\n",
    "\n",
    "    print(\"'\")\n",
    "    return chat_history\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üß† **Configuring the Research Assistant**\n",
    "\n",
    "\n",
    "\n",
    " Now we'll set up our research assistant by:\n",
    "\n",
    " 1. Defining the agent's name and instructions\n",
    "\n",
    " 2. Configuring the kernel and AI service\n",
    "\n",
    " 3. Setting up function choice behavior\n",
    "\n",
    " 4. Registering our plugins\n",
    "\n",
    " 5. Creating the agent with the configured settings\n",
    "\n",
    "\n",
    "\n",
    " The agent instructions are particularly important as they define:\n",
    "\n",
    " - The agent's role and capabilities\n",
    "\n",
    " - The workflow it should follow\n",
    "\n",
    " - How it should use its available tools\n",
    "\n",
    " - Where it should save different types of files\n",
    "\n",
    "## üîÑ **Setting the Function Choice Behavior**\n",
    "\n",
    "\n",
    "\n",
    " In Semantic Kernel, we have the ability to control the agent's choice of functions. This is done using the `FunctionChoiceBehavior` class.\n",
    "\n",
    "\n",
    "\n",
    " The code in this example sets it to `Required(auto_invoke=True)` which:\n",
    "\n",
    " - **Requires** the agent to choose at least one function when appropriate\n",
    "\n",
    " - **Auto-invokes** the chosen functions without additional confirmation\n",
    "\n",
    " - Allows up to 100 function invocations in a single conversation turn\n",
    "\n",
    "\n",
    "\n",
    " This can also be set to:\n",
    "\n",
    " - `FunctionChoiceBehavior.Auto()` - allows the agent to choose among the available functions or not choose any\n",
    "\n",
    " - `FunctionChoiceBehavior.NoneInvoke()` - instructs the agent to not choose any function (good for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the agent instructions\n",
    "AGENT_NAME = \"ResearchAssistant\"\n",
    "AGENT_INSTRUCTIONS = \"\"\"\n",
    "You are a helpful research assistant that can search for information on academic and general topics.\n",
    "\n",
    "Your capabilities include:\n",
    "- Searching for academic papers on arXiv\n",
    "- Searching the web using DuckDuckGo\n",
    "- Extracting and processing content from web pages\n",
    "- Generating research summaries\n",
    "- Creating data visualizations\n",
    "\n",
    "When given a research topic:\n",
    "1. First try to find relevant academic papers on arXiv\n",
    "2. If no relevant papers are found, use web search as a fallback\n",
    "3. Process and analyze the content you find\n",
    "4. Generate a summary of your findings\n",
    "5. Create visualizations when appropriate\n",
    "\n",
    "You should decide on your own which tools to use and in what order based on the user's needs.\n",
    "Always explain what you're doing and why.\n",
    "\n",
    "Important:\n",
    "- You can download PDF papers from ArXiv to the 'papers' directory\n",
    "- You should save visualizations to the 'visualizations' directory\n",
    "- Research summaries and save to the 'summaries' directory\n",
    "\"\"\"\n",
    "\n",
    "# Configure function calling behavior\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Required(auto_invoke=True)\n",
    "settings.function_choice_behavior.enable_kernel_functions = True\n",
    "settings.function_choice_behavior.maximum_auto_invoke_attempts = 10\n",
    "\n",
    "# Register all plugins\n",
    "kernel.add_plugin(ArXivPlugin(), plugin_name=\"arxiv\")\n",
    "kernel.add_plugin(WebSearchPlugin(), plugin_name=\"web\")\n",
    "kernel.add_plugin(ResearchPlugin(), plugin_name=\"research\")\n",
    "kernel.add_plugin(VisualizationPlugin(), plugin_name=\"visualization\")\n",
    "\n",
    "# Create the research agent\n",
    "agent = ChatCompletionAgent(\n",
    "    service_id=SERVICE_ID,\n",
    "    kernel=kernel,\n",
    "    name=AGENT_NAME,\n",
    "    instructions=AGENT_INSTRUCTIONS,\n",
    "    arguments=KernelArguments(settings=settings),\n",
    ")\n",
    "\n",
    "# Initialize chat history\n",
    "chat = ChatHistory()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üîç **Testing the Research Assistant**\n",
    "\n",
    "\n",
    "\n",
    " Let's create a helper function to test our research assistant with a simple query. This function:\n",
    "\n",
    " - Adds the user's question to the chat history\n",
    "\n",
    " - Prints the user's question\n",
    "\n",
    " - Streams the agent's response in real-time\n",
    "\n",
    " - Adds a newline at the end for readability\n",
    "\n",
    "\n",
    "\n",
    " We'll use this function to test our research assistant with a query about quantum computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def ask_research(question: str):\n",
    "    \"\"\"\n",
    "    Helper function to send a research query and stream the agent's response.\n",
    "\n",
    "    Args:\n",
    "        question: The research question or topic to investigate\n",
    "    \"\"\"\n",
    "    # Add the question to chat history\n",
    "    chat.add_user_message(question)\n",
    "    print(f\"User: {question}\")\n",
    "\n",
    "    # Stream the response\n",
    "    async for response in agent.invoke_stream(chat):\n",
    "        print(response.content, end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# Example usage with research queries\n",
    "# To run this in a Jupyter notebook cell:\n",
    "await ask_research(\"Research quantum computing\")\n",
    "\n",
    "# To run this in a regular Python script:\n",
    "# asyncio.run(ask_research(\"Research quantum computing\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## üñ•Ô∏è **Building an Interactive UI**\n",
    "\n",
    "\n",
    "\n",
    " To make our research assistant more user-friendly, we'll create an interactive UI using IPython widgets. This UI includes:\n",
    "\n",
    " - A text input for entering research topics\n",
    "\n",
    " - A button to start the research process\n",
    "\n",
    " - A text input for follow-up questions\n",
    "\n",
    " - A status indicator to show the current state\n",
    "\n",
    " - An output area to display the conversation\n",
    "\n",
    "\n",
    "\n",
    " This demonstrates how Semantic Kernel agents can be integrated into interactive applications, providing a more engaging user experience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResearchAssistantApp:\n",
    "    \"\"\"Interactive UI for the Research Assistant using IPython widgets.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.agent = None\n",
    "        self.chat_history = None\n",
    "        self.kernel = None\n",
    "        self.service_id = None  # Store the service_id\n",
    "        self.create_ui()\n",
    "\n",
    "    def create_ui(self):\n",
    "        \"\"\"Create and display the UI components.\"\"\"\n",
    "        # Define UI component dimensions\n",
    "        input_width = \"70%\"\n",
    "        button_width = \"20%\"\n",
    "\n",
    "        # Create the query input field\n",
    "        self.query_input = widgets.Text(\n",
    "            value=\"\",\n",
    "            placeholder=\"Enter a research topic...\",\n",
    "            description=\"Query:\",\n",
    "            layout=widgets.Layout(width=input_width),\n",
    "        )\n",
    "\n",
    "        # Create the search button\n",
    "        self.search_button = widgets.Button(\n",
    "            description=\"Research\",\n",
    "            button_style=\"primary\",\n",
    "            layout=widgets.Layout(width=button_width),\n",
    "        )\n",
    "        self.search_button.on_click(self.on_search_clicked)\n",
    "\n",
    "        # Create the input box (horizontal container)\n",
    "        self.input_box = widgets.HBox([self.query_input, self.search_button])\n",
    "\n",
    "        # Create the follow-up message input (initially disabled)\n",
    "        self.message_input = widgets.Text(\n",
    "            value=\"\",\n",
    "            placeholder=\"Ask a follow-up question...\",\n",
    "            description=\"Message:\",\n",
    "            layout=widgets.Layout(width=input_width),\n",
    "            disabled=True,\n",
    "        )\n",
    "\n",
    "        # Create the send button (initially disabled)\n",
    "        self.send_button = widgets.Button(\n",
    "            description=\"Send\",\n",
    "            button_style=\"info\",\n",
    "            layout=widgets.Layout(width=button_width),\n",
    "            disabled=True,\n",
    "        )\n",
    "        self.send_button.on_click(self.on_send_clicked)\n",
    "\n",
    "        # Create the message box (horizontal container)\n",
    "        self.message_box = widgets.HBox([self.message_input, self.send_button])\n",
    "\n",
    "        # Create the output display area\n",
    "        self.output = widgets.Output(\n",
    "            layout=widgets.Layout(\n",
    "                border=\"1px solid #ddd\",\n",
    "                padding=\"10px\",\n",
    "                height=\"500px\",\n",
    "                overflow_y=\"auto\",\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Create the status indicator\n",
    "        self.status = widgets.HTML(value=\"<i>Ready to start research.</i>\")\n",
    "\n",
    "        # Display all UI components\n",
    "        display(self.input_box)\n",
    "        display(self.message_box)\n",
    "        display(self.status)\n",
    "        display(self.output)\n",
    "\n",
    "    async def initialize(self):\n",
    "        \"\"\"Initialize the kernel, plugins, and agent.\"\"\"\n",
    "        self.status.value = \"<i>Initializing kernel and plugins...</i>\"\n",
    "\n",
    "        # Create a new kernel\n",
    "        self.kernel = Kernel()\n",
    "        self.service_id = \"agent\"\n",
    "\n",
    "        # Register the AI service\n",
    "        self.kernel.add_service(AzureChatCompletion(service_id=self.service_id))\n",
    "\n",
    "        # Configure function calling behavior\n",
    "        settings = self.kernel.get_prompt_execution_settings_from_service_id(\n",
    "            service_id=self.service_id\n",
    "        )\n",
    "        settings.function_choice_behavior = FunctionChoiceBehavior.Required(\n",
    "            auto_invoke=True\n",
    "        )\n",
    "        settings.function_choice_behavior.enable_kernel_functions = True\n",
    "        settings.function_choice_behavior.maximum_auto_invoke_attempts = 100\n",
    "\n",
    "        # Register all plugins\n",
    "        self.kernel.add_plugin(ArXivPlugin(), plugin_name=\"arxiv\")\n",
    "        self.kernel.add_plugin(WebSearchPlugin(), plugin_name=\"web\")\n",
    "        self.kernel.add_plugin(ResearchPlugin(), plugin_name=\"research\")\n",
    "        self.kernel.add_plugin(VisualizationPlugin(), plugin_name=\"visualization\")\n",
    "\n",
    "        # Create the agent with the configured settings\n",
    "        self.agent = ChatCompletionAgent(\n",
    "            service_id=self.service_id,\n",
    "            kernel=self.kernel,\n",
    "            name=AGENT_NAME,\n",
    "            instructions=AGENT_INSTRUCTIONS,\n",
    "            arguments=KernelArguments(settings=settings),\n",
    "        )\n",
    "\n",
    "        # Initialize chat history\n",
    "        self.chat_history = ChatHistory()\n",
    "\n",
    "        # Update status\n",
    "        self.status.value = \"<i>Ready!</i>\"\n",
    "\n",
    "    def on_search_clicked(self, button):\n",
    "        \"\"\"Handle search button clicks.\"\"\"\n",
    "        # Get the query text\n",
    "        query = self.query_input.value\n",
    "\n",
    "        # Validate input\n",
    "        if not query:\n",
    "            self.status.value = (\n",
    "                \"<b style='color:red'>Please enter a research topic!</b>\"\n",
    "            )\n",
    "            return\n",
    "\n",
    "        # Disable inputs during processing\n",
    "        self.query_input.disabled = True\n",
    "        self.search_button.disabled = True\n",
    "\n",
    "        # Update status\n",
    "        self.status.value = \"<i>Researching...</i>\"\n",
    "\n",
    "        # Clear previous output\n",
    "        with self.output:\n",
    "            clear_output()\n",
    "\n",
    "        # Start asynchronous processing\n",
    "        asyncio.create_task(self.process_query(query))\n",
    "\n",
    "    async def process_query(self, query):\n",
    "        # Initialize if needed\n",
    "        if self.kernel is None:\n",
    "            await self.initialize()\n",
    "\n",
    "        # Create new chat history\n",
    "        self.chat_history = ChatHistory()\n",
    "\n",
    "        # Add the query to chat history\n",
    "        self.chat_history.add_user_message(f\"Research this topic: {query}\")\n",
    "\n",
    "        # Display user message\n",
    "        with self.output:\n",
    "            display(Markdown(f\"**User**: Research this topic: {query}\"))\n",
    "\n",
    "        # Get agent response\n",
    "        with self.output:\n",
    "            display(Markdown(\"**ResearchAssistant**: _Thinking..._\"))\n",
    "\n",
    "        # Collect response parts\n",
    "        response_parts = []\n",
    "\n",
    "        # Stream the response\n",
    "        async for content in self.agent.invoke_stream(self.chat_history):\n",
    "            # Collect non-function content\n",
    "            if (\n",
    "                not any(\n",
    "                    isinstance(item, (FunctionCallContent, FunctionResultContent))\n",
    "                    for item in content.items\n",
    "                )\n",
    "                and content.content.strip()\n",
    "            ):\n",
    "                response_parts.append(content.content)\n",
    "                # Update the output with the current response\n",
    "                with self.output:\n",
    "                    clear_output(wait=True)\n",
    "                    display(Markdown(f\"**User**: Research this topic: {query}\"))\n",
    "                    display(\n",
    "                        Markdown(f\"**ResearchAssistant**: {''.join(response_parts)}\")\n",
    "                    )\n",
    "\n",
    "        # Enable follow-up messages\n",
    "        self.message_input.disabled = False\n",
    "        self.send_button.disabled = False\n",
    "        self.status.value = \"<i>Research complete. You can ask follow-up questions.</i>\"\n",
    "\n",
    "    def on_send_clicked(self, button):\n",
    "        message = self.message_input.value\n",
    "        if not message:\n",
    "            self.status.value = \"<b style='color:red'>Please enter a message!</b>\"\n",
    "            return\n",
    "\n",
    "        # Disable input while processing\n",
    "        self.message_input.disabled = True\n",
    "        self.send_button.disabled = True\n",
    "        self.status.value = \"<i>Processing...</i>\"\n",
    "\n",
    "        # Process message asynchronously\n",
    "        asyncio.create_task(self.process_message(message))\n",
    "\n",
    "        # Clear the input\n",
    "        self.message_input.value = \"\"\n",
    "\n",
    "    async def process_message(self, message):\n",
    "        # Add the message to chat history\n",
    "        self.chat_history.add_user_message(message)\n",
    "\n",
    "        # Display user message\n",
    "        with self.output:\n",
    "            display(Markdown(f\"**User**: {message}\"))\n",
    "\n",
    "        # Collect response parts\n",
    "        response_parts = []\n",
    "\n",
    "        # Stream the response\n",
    "        async for content in self.agent.invoke_stream(self.chat_history):\n",
    "            # Collect non-function content\n",
    "            if (\n",
    "                not any(\n",
    "                    isinstance(item, (FunctionCallContent, FunctionResultContent))\n",
    "                    for item in content.items\n",
    "                )\n",
    "                and content.content.strip()\n",
    "            ):\n",
    "                response_parts.append(content.content)\n",
    "                # Update the output\n",
    "                with self.output:\n",
    "                    display(\n",
    "                        Markdown(f\"**ResearchAssistant**: {''.join(response_parts)}\")\n",
    "                    )\n",
    "\n",
    "        # Re-enable input\n",
    "        self.message_input.disabled = False\n",
    "        self.send_button.disabled = False\n",
    "        self.status.value = \"<i>Ready for more questions.</i>\"\n",
    "\n",
    "app = ResearchAssistantApp()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
